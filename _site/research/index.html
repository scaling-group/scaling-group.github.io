<!DOCTYPE html>
<html>

  <head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Scaling Group: Research</title>
  <meta name="description" content="Scaling Group: Research">
  <link rel="stylesheet" href="http://localhost:4000/css/main.css">
  <link rel="canonical" href="http://localhost:4000/research/">

  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>

  


</head>

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/css/bootstrap.min.css">

  <body>

    <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container-fluid">
	<div class="navbar-header">
	  <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-collapse-1" aria-expanded="false">
		<span class="sr-only">Toggle navigation</span>
		<span class="icon-bar"></span>
		<span class="icon-bar"></span>
		<span class="icon-bar"></span>
	  </button>
	
    <a class="navbar-brand" href="http://localhost:4000/">Scientific Computing and Intelligence Group</a>
	</div>
	<div class="collapse navbar-collapse" id="navbar-collapse-1">
	  <ul class="nav navbar-nav navbar-right">
		<li><a href="http://localhost:4000/">Home</a></li>
		<li><a href="http://localhost:4000/team">Team</a></li>
		<li><a href="http://localhost:4000/openings">Openings</a></li>
		<li><a href="http://localhost:4000/publications">Publications</a></li>
		<li><a href="http://localhost:4000/research">Research</a></li>
		<li><a href="http://localhost:4000/news">News</a></li>
	  </ul>
	</div>
  </div>
</div>


    <div class="container-fluid">
      <div class="row">
        <div id="textid" class="col-sm-12">
  <h1 id="research">Research</h1>

<!-- Here are some themes that we currently work on: -->

<p><strong>Foundation Scientific Learning Models</strong></p>

<p>Can we build a single large model for a wide range of scientific problems?</p>

<p>We proposed a new framework for scientific machine learning, namely <strong>“In-Context Operator Learning”</strong> and the corresponding model
<strong>“In-Context Operator Networks”</strong> (ICON). A distinguishing feature of ICON is its ability to learn operators from numerical prompts during the inference phase, without weight adjustments. A single ICON model can tackle a wide range of tasks involving different operators, since it is trained as a generalist operator learner, rather than being tuned to approximate a specific operator. This is similar to how a single Large Language Model can solve a variety of natural language processing tasks specified by the language prompt. View the tutorial code in our <a href="https://github.com/scaling-group/icon-tutorial">GitHub repository</a></p>

<p>We have a series of works on ICON.</p>
<ul>
  <li>In our first paper, we proposed In-Context Operator Learning and In-Context Operator Networks. We showed how <strong>a single ICON model (without fine-tuning) manages 19 distinct problem types</strong>, encompassing forward and inverse ODE, PDE, and mean-field control problems, with infinite operators in each problem type. <a href="https://www.pnas.org/doi/10.1073/pnas.2310142120">paper</a></li>
  <li>We improved the model architecture of ICON to improve efficiency and support multi-modal learning, i.e., prompting the model with human language and LaTeX equations, apart from numerical data (See the following figure). <a href="https://arxiv.org/pdf/2308.05061.pdf">paper</a></li>
  <li>We showed how a single ICON model can make forward and reverse predictions for conservation laws with different flux functions and time strides, and <strong>generalize well to PDEs with new forms</strong>, without any fine-tuning. We also showed prompt engineer techniques to broaden the capability of ICON. <a href="https://www.sciencedirect.com/science/article/pii/S0021999124006272">paper</a></li>
  <li>We proposed VICON, incorporating a vision transformer architecture to efficiently process 2D functions in multi-physics fluid dynamics prediction tasks. <a href="https://arxiv.org/pdf/2411.16063">paper</a></li>
</ul>

<hr />
<p><img src="http://localhost:4000/images/papers/icon-multi-modal_numerical.png" alt="" style="width: 70%; float: center; margin: 0px" /></p>

<p>Figure 1: Diagram for multi-modal in-context operator learning. The model learns the operator from the textual prompt and/or numerical examples, and applys to the question to make the prediction, with one forward pass.</p>

<hr />
<p><img src="http://localhost:4000/images/papers/icon-mfg.png" alt="" style="width: 100%; float: center; margin: 0px" /></p>

<p>Figure 2: Illustration of in-context operator learning for a mean-field control problem. The blue/red/black dots represent the data points in the prompt. The ICON model is able to learn the underlying operator from three examples and solve the problem with one forward pass.</p>

<hr />

<p>Tracing the evolution of neural equation solvers, we see a three-act progression: <strong>Act 1</strong> focused on approximating the solution function, e.g., Physics-Informed Neural Networks, while <strong>Act 2</strong> shifted towards approximating the solution operator, e.g., Fourier Neural Operator, DeepONet. ICON can be viewed as an early attempt of <strong>Act 3</strong>, where the model acts like an intelligent agent that adapts to new physical systems and tasks.</p>

<!-- **Uncertainty Quantification**

Coming soon... -->

<p><strong>Previous Works</strong></p>

<p>Here are some of Yang Liu’s previous works during Ph.D. years:</p>

<p>– Bayesian Inference for PDEs with PI-GANs and B-PINNs</p>

<p>This series of works aim to address the following challenge: How to perform stochatic modeling and uncertainty quantification for physical systems, with the knowledge of the governing equations and scattered/noisy measurements?</p>

<p>To accurately model the distribution within physical systems (typically defined within a functional space) we proposed <a href="https://epubs.siam.org/doi/abs/10.1137/18M1225409?journalCode=sjoce3">Physics-Informed Generative Adversarial Networks (PI-GANs)</a>. This method effectively integrates physical principles and data, making it suitable for modeling stochastic physical systems or for learning prior distributions from historical data. When combined with our proposed <a href="https://www.sciencedirect.com/science/article/abs/pii/S0021999120306872">Bayesian Physics-Informed Neural Networks (B-PINNs)</a>, which establish likelihoods based on governing equations and observational data, this framework allows for <a href="https://www.sciencedirect.com/science/article/abs/pii/S0021999122001358">systematic Bayesian inference on PDEs</a>.</p>

<p>– Learning Optimal Transport Map and Particle Dynamics</p>

<p>Being the first to draw the connection between deep generative models and the continuous flow formulation of optimal transport, we proposed <a href="https://ieeexplore.ieee.org/document/9233438">potential flow generator</a> as a plug-and-play generator module for different GANs and flow-based models. With a special ODE-based network architecture and an augmented loss term tied to the Hamilton-Jacobi equation derived from the optimal transport condition, the potential flow generator not only transports the source distribution to the target one, but also approximates the optimal transport map.</p>

<hr />

<p><img src="http://localhost:4000/images/papers/WGAN_all.png" alt="" style="width: 40%; float: center; margin: 0px" />
<img src="http://localhost:4000/images/papers/flow_all.png" alt="" style="width: 45%; float: center; margin: 0px" /></p>

<p>Potential flow generator in GANs (left 3 columns) and normalizing flow (right 3 columns). The first row shows the samples or the unnormalized densities of source distributions \(\mu\) (in purple) and target distributions \(\nu\) (in orange), the second row shows the learned optimal transport maps \(G\) and the push forward distributions \(G_{\#}\mu\).</p>

<hr />

<p>Subsequently, we extended this framework to <a href="https://epubs.siam.org/doi/abs/10.1137/21M1413018">inference of particle dynamics from paired/unpaired observations of particles</a>, encompassing non-local particle interactions and high-dimensional stochastic particle dynamics.</p>

<p>These works were cited by other great works in <a href="https://www.pnas.org/doi/10.1073/pnas.1922204117">high-dimensional mean-field problems</a>, <a href="https://www.nature.com/articles/s42256-023-00763-w">single-cell transcriptomics</a>, and <a href="https://arxiv.org/pdf/2210.02747">flow matching for generative modeling</a>.</p>

<p><strong>… and more</strong></p>

</div>

      </div>
    </div>

    <!-- 
<div id="footer" class="panel">
  <div class="panel-footer">
	<div class="container-fluid">
	  <div class="row"> -->

		<!-- <div class="col-sm-4">

		</div> -->

		<!-- <div class="col-sm-4">
		  Email: yangliu at nus dot edu dot sg
		</div> -->
		
		<!-- <div class="col-sm-4">
		  Office:<br />
			Room 08-09, Block S17, 
			10 Lower Kent Ridge Road
			Singapore 119076<br />
            (<a href="https://maps.app.goo.gl/M5b6gBTZ1zPVm57q8">Maps</a>, <a href="https://www.math.nus.edu.sg/contact-us/where-we-are/">Directions</a>)
		</div> 
	  
	</div>
	</div>
  </div>
</div>

<script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
<script src="http://localhost:4000/js/bootstrap.min.js"></script>

-->

<!-- Add jQuery -->
<script src="https://code.jquery.com/jquery-3.5.1.min.js"></script>
<!-- Add Bootstrap JavaScript -->
<script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.4.1/js/bootstrap.min.js"></script>


  </body>

</html>
